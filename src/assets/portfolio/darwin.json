{
    "id": "darwin",
    "name": "DARwIn-OP Humanoid Dance Synthesis",
    "start_date": "2013-02-01",
    "end_date": "2013-12-06",
    "contributors": [
        {
            "name": "David Grunberg",
            "link": "http://music.ece.drexel.edu/people/dgrunberg"
        },
        {
            "name": "Stephanie Tjiong",
            "link": "http://stjiong.wix.com/portfolio"
        }
    ],
    "short_desc": "The DARwIn-OP Dance Synthesis project is my current primary project in the MET-lab.  I am working with the DARwIn-OP to create real-time procedural dance generation using Markov-Chain algorithms and Beat-Tracking audio processing to teach robots to dance more like humans.",
    "long_desc": "### Introduction\n[The DARwIn-OP](http://www.romela.org/main/DARwIn_OP:_Open_Platform_Humanoid_Robot_for_Research_and_Education) (Dynamic Anthromorphic Robot with Intelligence) is a miniature humanoid robot with advanced computational power and dynamic motion abilities which allow him to move in similar ways to humans.   The project that I am doing with DARwIn is focused on procedural dance generation  through the use of Markov-Chain algorithms.  Markov-Chain algorithms are a pattern analysis tool which are usually used to generate real-sounding text based off of a sample text.  I’ve adapted this algorithm to analyze dance sequences in order to generate seemingly non-random dance performances that flow smoothly from position to another.  This program also implements a Beat-Tracker developed by a MET-lab graduate student, David Grunberg, which allows DARwIn to track audio in real-time and dance to the beat.\n### Dance Library and Sequencing\nIn order to make DARwIn dance, I first had to teach him some \"moves.\"  I worked with my friend Stephanie Tjiong, who is an experienced dancer, to create a large (and still growing) set of dance moves and sequences.  Each move represents a position, and we can chain these moves together in series, allowing for possibilities to branch to different moves.  Once a satisfactory number of sequences has been made, we may run the analyzer tool on them to find the probability of one move following another move.  Then, while DARwIn is actually dancing, we may utilize the tool to choose the next move using the markov-chain to decide what would look best based on the current position.\n### Beat Tracking\nAs humans, we find it very easy to follow the beat of a song and take note of when the beat changes.  However, this is not such a simple task for computers – in fact, it turns out to be quite a difficult task!  A fellow researcher and Ph.D. student from the MET-lab, David Grunberg, developed a robust Beat Tracking system which listens to audio in real time and is able to keep track of whenever there is a beat in the song.  You can read the full paper on the beat-tracker on [the MET-Lab website.](http://music.ece.drexel.edu/files/Navigation/Publications/iros2011.pdf)\n\nIn the DARwIn Dance Synthesis project, we employ this Beat Tracker to execute dance moves whenever a beat is heard in the song DARwIn is listening to.  The motivation for implementing this system is so that the DARwIn robot does not need any pre-programmed timing nor any forecasting of when a song is changing in order to dance as humans do.",
    "languages": [
        "C",
        "C++",
        "DARwIn-OP API"
    ],
    "images": {
        "banner": "assets/images/portfolio/banner/darwin.jpg",
        "frontpage": "assets/images/portfolio/frontpage/darwin.jpg",
        "gallery": "assets/images/portfolio/gallery/darwin.jpg",
        "feature": [
            "assets/images/portfolio/images/darwin",
            "assets/images/portfolio/images/darwin2",
            "assets/images/portfolio/images/darwin3",
            "assets/images/portfolio/images/darwin4",
            "assets/images/portfolio/images/darwin5",
            "assets/images/portfolio/images/darwin6",
            "assets/images/portfolio/images/darwin7",
            "assets/images/portfolio/images/darwin8"
        ]
    }
}